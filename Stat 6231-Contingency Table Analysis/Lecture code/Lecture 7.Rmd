---
title: "Lecture 7"
output:
  html_document:
    toc: true
    number_sections: true
    toc_depth: 2
---

# Logistic Regression Example: Birthweight Data

This example will use data studying risk factors for low birth weight in $n=189$ women.  We are interested in modeling the probability of low birth weight as a function of mother's age, mother's weight, mother's race and whether the mother smokes or not.  The variables are coded as:

1. low: 1 = low birth weight (<2500g), 0 = not low birth weight #
2. age: age of mother in years #
3. lwt: weight of mother in pounds #
4. race: white, black, other #
5. smoke: 1 = Yes, 0 = No #

```{r}
setwd("H:/GWU/Spring 2018/Lectures")
rm(list=ls())
data = read.table("birthweight.txt", header = T)

names(data)
dim(data)

attach(data)
summary(data)
```

## Model Fit

```{r}
logit = glm(low ~ age + lwt + smoke, family = binomial(link=logit))
summary(logit)
logit.coef = coefficients(logit)
logit.coef
exp(logit.coef)
```

Looking at the coefficient estimates, we can interpret the effect of each of the predictors on the probability of low birth weight.  For example, $exp(\hat{\beta}_{smoke}) = `r exp(logit.coef)[4]`$ means that a smoker ($smoke = 1$) is almost twice as likely to have a baby with low birth weight compared to a non-smoker, holding other covariates constant.  In terms of log odds, being a smoker increases the log odds by $\hat{\beta}_{smoke} = `r logit.coef[4]`$.

On the other hand, a year increase in mother's age means that a mother is $1/exp(\hat{\beta}_{age}) = `r 1/exp(logit.coef)[2]`$ times less likely to have a baby with low birth weight, holding other covariates constant.  In terms of the log odds, for every one year increase in age, the log odds of low birth weight decreases by $\hat{\beta}_{age} = `r logit.coef[2]`$.

## Inference: Goddness-of-Fit (GOF)

```{r}
logit$null.deviance - logit$deviance
qchisq(.05,3,lower.tail=FALSE)
```

The difference between the residual deviance and null deviance is used to test $H_0:$ intercept only model vs. $H_a:$ proposed model.  We reject the null of the intercept only model in favor of the model that includes $age, lwt,$ and $smoke$ because $`r logit$null.deviance - logit$deviance` > \chi^2_3 = `r qchisq(.05,3,lower.tail=FALSE)`$.

## Inference: Predictor Effects

Referring to the model output, we find that the Wald hypothesis tests indicate that $lwt$ and $smoke$ are statistically significant at the $\alpha=.05$ level.  We can also calculate 95\% Wald confidence intervals for the log odds and for the odds for each predictor individually.  For example,

```{r}
lb = logit.coef[4] - qnorm(.05/2,lower.tail=FALSE) * .32581
ub = logit.coef[4] + qnorm(.05/2,lower.tail=FALSE) * .32581
c(lb,ub)
exp(c(lb,ub))
```

The 95\% CI for $\beta_{smoke}$ is $(`r c(lb,ub)`)$ and for $exp(\beta_{smoke})$ is ($`r exp(c(lb,ub))`$).  Thus we are 95\% confident that the interval $(`r exp(c(lb,ub))`)$ contains the true $exp(\beta_{smoke})$. The CI for $\beta_{smoke}$ does not contain $0$ and the CI for $exp(\beta_{smoke})$ does not contain $1$, consistent with the finding that the predictor $smoke$ is statistically significant.

## Assessing Predictor Effects

We can look at the predicted probabilities to visualize the effects of the covariates.  For example, consider the effect of $age$ on the probability of a low birth weight baby for a 120 pound smoker.  To do this, we evaluate the linear predictor at fixed values of $lwt$ and $smoke$ over the range of $age$ and apply the logit tranformation to obtain the predicted probabilities.

```{r}
# 120 pound smoker #
newX = cbind(1, seq(from=min(age), to=max(age), by=1), 120, 1)
eta = newX %*% logit.coef
pred.prob = exp(eta) / (1 + exp(eta))
jitter.low = jitter(low,.1)
plot(age, jitter.low, main = "Age vs. Low Birth Weight by Smoker", xlab = "Mother's Age", ylab = "Low Birth Weight Predicted Probability",col='red')
points(age[smoke==0], jitter.low[smoke==0], col='blue') 
lines(seq(from=min(age), to=max(age), by=1), pred.prob, col='red')

# 120 pound non-smoker #
newX = cbind(1, seq(from=min(age), to=max(age), by=1), 120, 0)
eta = newX %*% logit.coef
pred.prob = exp(eta) / (1 + exp(eta))
lines(seq(from=min(age), to=max(age), by=1), pred.prob, col='blue',lty=2)
legend(37, 1, legend=c("Smoker", "Non-Smoker"), col=c("red", "blue"), lty=1:2, cex=.75)
```

## Model Comparison

We can use deviances to compare nested models.  For example, should we include race as a covariate?

```{r}
Black = race == "black"
Other = race == "other"

logit2 = glm(low ~ age + lwt + smoke + Black + Other, family = binomial(link=logit))
summary(logit2)

diff.dev = deviance(logit) - deviance(logit2)
diff.dev

qchisq(.95,2)
```

The difference between the residual deviances is used to test $H_0:$ reduced model ($\beta_{black}=\beta_{other} = 0$) vs. $H_a:$ full model ($\beta_{black}\neq0$ or $\beta_{other} \neq 0$).  We reject the null of the reduced model in favor of the model that includes $race$ because $`r diff.dev` > \chi^2_2 = `r qchisq(.05,2,lower.tail=FALSE)`$.

